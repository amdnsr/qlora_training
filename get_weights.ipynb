{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kokil/anaconda3/envs/qlora_conda_3912_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/kokil/anaconda3/envs/qlora_conda_3912_env/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda111_nocublaslt.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n",
      "CUDA SETUP: Detected CUDA version 111\n",
      "CUDA SETUP: Loading binary /home/kokil/anaconda3/envs/qlora_conda_3912_env/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda111_nocublaslt.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kokil/anaconda3/envs/qlora_conda_3912_env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/kokil/anaconda3/envs/qlora_conda_3912_env did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/kokil/anaconda3/envs/qlora_conda_3912_env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/home/kokil/anaconda3/envs/qlora_conda_3912_env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/home/kokil/anaconda3/envs/qlora_conda_3912_env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n",
      "/home/kokil/anaconda3/envs/qlora_conda_3912_env/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-12 20:33:39.066692\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# import fire\n",
    "# import gradio as gr\n",
    "import torch\n",
    "import transformers\n",
    "from peft import PeftModel\n",
    "from transformers import GenerationConfig, LlamaForCausalLM, LlamaTokenizer, BitsAndBytesConfig, AutoModelForCausalLM\n",
    "\n",
    "from utils.callbacks import Iteratorize, Stream\n",
    "from utils.prompter import Prompter\n",
    "\n",
    "\n",
    "device_no = 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = f\"cuda:{device_no}\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "try:\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "except:  # noqa: E722\n",
    "    pass\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# !mkdir adapter_model\n",
    "\n",
    "# !cp -r /content/drive/MyDrive/ml-models/llama_training_reddit_colab_1_ep_128b/adapter_model/ adapter_model\n",
    "\n",
    "# template folder\n",
    "# alpaca.json\n",
    "# utils folder\n",
    "\n",
    "# model_name = \"amdnsr/llama-7b-hf\"\n",
    "base_model = \"amdnsr/llama-7b-hf\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from utils.prompter import Prompter\n",
    "\n",
    "add_eos_token: bool = False\n",
    "cutoff_len = CUTOFF_LEN = 256\n",
    "train_on_inputs = False\n",
    "prompt_template_name: str = \"alpaca\"\n",
    "prompter = Prompter(prompt_template_name)\n",
    "\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    input_ids,\n",
    "    # instruction,\n",
    "    # input=None,\n",
    "    temperature=0.1,\n",
    "    top_p=0.75,\n",
    "    top_k=40,\n",
    "    num_beams=4,\n",
    "    # max_new_tokens is set to 8, as for our model, only a single word prediction is needed\n",
    "    max_new_tokens=32,\n",
    "    stream_output=False,\n",
    "    **kwargs,\n",
    "):\n",
    "    # prompt = prompter.generate_prompt(instruction, input)\n",
    "    # inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    # input_ids = inputs[\"input_ids\"].to(device)\n",
    "    input_ids = torch.tensor(input_ids).unsqueeze(0).to(device)\n",
    "    generation_config = GenerationConfig(\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        num_beams=num_beams,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    generate_params = {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"generation_config\": generation_config,\n",
    "        \"return_dict_in_generate\": True,\n",
    "        \"output_scores\": True,\n",
    "        \"max_new_tokens\": max_new_tokens,\n",
    "    }\n",
    "\n",
    "    if stream_output:\n",
    "        # Stream the reply 1 token at a time.\n",
    "        # This is based on the trick of using 'stopping_criteria' to create an iterator,\n",
    "        # from https://github.com/oobabooga/text-generation-webui/blob/ad37f396fc8bcbab90e11ecf17c56c97bfbd4a9c/modules/text_generation.py#L216-L243.\n",
    "\n",
    "        def generate_with_callback(callback=None, **kwargs):\n",
    "            kwargs.setdefault(\n",
    "                \"stopping_criteria\", transformers.StoppingCriteriaList()\n",
    "            )\n",
    "            kwargs[\"stopping_criteria\"].append(\n",
    "                Stream(callback_func=callback)\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                model.generate(**kwargs)\n",
    "\n",
    "        def generate_with_streaming(**kwargs):\n",
    "            return Iteratorize(\n",
    "                generate_with_callback, kwargs, callback=None\n",
    "            )\n",
    "\n",
    "        with generate_with_streaming(**generate_params) as generator:\n",
    "            for output in generator:\n",
    "                # new_tokens = len(output) - len(input_ids[0])\n",
    "                decoded_output = tokenizer.decode(output)\n",
    "\n",
    "                if output[-1] in [tokenizer.eos_token_id]:\n",
    "                    break\n",
    "\n",
    "                return prompter.get_response(decoded_output)\n",
    "        return  # early return for stream_output\n",
    "\n",
    "    # Without streaming\n",
    "    with torch.no_grad():\n",
    "        generation_output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            generation_config=generation_config,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "        )\n",
    "    s = generation_output.sequences[0]\n",
    "    output = tokenizer.decode(s)\n",
    "    return prompter.get_response(output)\n",
    "\n",
    "\n",
    "\n",
    "def tokenize(prompt, add_eos_token=True):\n",
    "    # there's probably a way to do this with the tokenizer settings\n",
    "    # but again, gotta move fast\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=cutoff_len,\n",
    "        padding=False,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "    if (\n",
    "        result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "        and len(result[\"input_ids\"]) < cutoff_len\n",
    "        and add_eos_token\n",
    "    ):\n",
    "        result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "        result[\"attention_mask\"].append(1)\n",
    "\n",
    "    # result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = prompter.generate_prompt(\n",
    "        data_point[\"instruction\"],\n",
    "        data_point[\"input\"],\n",
    "        # data_point[\"output\"],\n",
    "    )\n",
    "    tokenized_full_prompt = tokenize(full_prompt)\n",
    "    # if not train_on_inputs:\n",
    "    #     user_prompt = prompter.generate_prompt(\n",
    "    #         data_point[\"instruction\"], data_point[\"input\"]\n",
    "    #     )\n",
    "    #     tokenized_user_prompt = tokenize(\n",
    "    #         user_prompt, add_eos_token=add_eos_token\n",
    "    #     )\n",
    "    #     user_prompt_len = len(tokenized_user_prompt[\"input_ids\"])\n",
    "\n",
    "    #     if add_eos_token:\n",
    "    #         user_prompt_len -= 1\n",
    "\n",
    "    #     tokenized_full_prompt[\"labels\"] = [\n",
    "    #         -100\n",
    "    #     ] * user_prompt_len + tokenized_full_prompt[\"labels\"][\n",
    "    #         user_prompt_len:\n",
    "    #     ]  # could be sped up, probably\n",
    "    return tokenized_full_prompt\n",
    "\n",
    "\n",
    "\n",
    "print(datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n",
      "Loading checkpoint shards: 100%|██████████| 33/33 [00:22<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    # quantization_config=bnb_config,\n",
    "    # device_map={\"\": device_no},\n",
    "    device_map=\"auto\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "tokenizer = LlamaTokenizer.from_pretrained(base_model)\n",
    "tokenizer.pad_token_id = (\n",
    "    0  # unk. we want this to be different from the eos token\n",
    ")\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # model = torch.compile(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    lora_weights,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "print(\"reached here\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"gab\"\n",
    "dataset_home = \"/home/kokil/ahmad/benchmarking_llms/projects/qlora_training/create_dataset_jsons_aadish\"\n",
    "model_name = \"llama\"\n",
    "model_adapter_output_home = \"/home/kokil/ahmad/benchmarking_llms/projects/qlora_training/model_adapter_output_home\"\n",
    "classifier_training_pickle_output_home = \"/home/kokil/ahmad/benchmarking_llms/projects/qlora_training/model_adapter_output_home/classifier_training_pickle_output_home\"\n",
    "INPUT_DIR = os.path.join(model_adapter_output_home, model_name, dataset_name)\n",
    "OUTPUT_DIR = os.path.join(classifier_training_pickle_output_home, model_name, dataset_home)\n",
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "lora_weights = INPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_path = os.path.join(dataset_home, f\"{dataset_name}.json\")\n",
    "# data_path = \"reddit.json\"\n",
    "from datasets import load_dataset\n",
    "data = load_dataset(\"json\", data_files=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = data[\"train\"].train_test_split(\n",
    "    # test_size=200, shuffle=True, seed=42\n",
    "    train_size = 900, test_size=100, shuffle=True, seed=42\n",
    ")\n",
    "train_data = (\n",
    "    # train_val[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "    train_val[\"train\"].map(generate_and_tokenize_prompt)\n",
    ")\n",
    "val_data = (\n",
    "    # train_val[\"test\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "    train_val[\"test\"].map(generate_and_tokenize_prompt)\n",
    ")\n",
    "\n",
    "# data = (\n",
    "#     data[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'instruction', 'output', 'input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEUTRAL'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-12 20:37:17.948205\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "# train_stats = trainer.get_training_stats()\n",
    "# print(train_stats)\n",
    "print(datetime.now())\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'instruction', 'output', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 900\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = train_data[0][\"input_ids\"]\n",
    "input_ids = torch.tensor(input_ids).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_hidden_state_of_last_token(model, input_ids):\n",
    "    \"\"\"\n",
    "    The model can be either LlamaForCausalLM or PeftModelForCausalLM, so, we can't directly take model.model to get to the LlamaModel as in the latter case, model.model is actually LlamaForCausalLM, and we'll have to do model.model.model, so instead, we'll do model.get_decoder() as this function is only in and is not overridden when doing the addition with the adapter\n",
    "\n",
    "    model = PeftModel.from_pretrained(\n",
    "        model, # adapter_folder\n",
    "        lora_weights,\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    input_ids = torch.tensor(input_ids).unsqueeze(0).to(device)\n",
    "\n",
    "    # BaseModelOutputWithPast\n",
    "    llama_base_model_output = model.get_decoder()(input_ids, output_hidden_states=True, return_dict=True)\n",
    "\n",
    "    # the above is (1, token_length, 4096), where token_length is the no of input tokens, i.e. len(input_ids)\n",
    "\n",
    "    # now if we want to get the last token's last hidden layer, we need to do\n",
    "    return llama_base_model_output[0][-1]\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, data):\n",
    "#         self.data = data\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x, y = self.data[idx]\n",
    "#         return {\n",
    "#             'input': x,\n",
    "#             'label': y\n",
    "#         }\n",
    "\n",
    "\n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, data):\n",
    "#         self.last_hidden_state_of_last_token = data['last_hidden_state_of_last_token']\n",
    "#         self.label = data['label']\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.last_hidden_state_of_last_token)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return {\n",
    "#             'last_hidden_state_of_last_token': self.last_hidden_state_of_last_token[idx],\n",
    "#             'label': self.label[idx]\n",
    "#         }\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.last_hidden_state_of_last_token = data['last_hidden_state_of_last_token']\n",
    "        self.label = data['label']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.last_hidden_state_of_last_token)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'last_hidden_state_of_last_token': self.last_hidden_state_of_last_token[idx],\n",
    "            'label': self.label[idx]\n",
    "        }\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Dataset(features={list(self[0].keys())}, num_rows={len(self)})\"\n",
    "\n",
    "\n",
    "\n",
    "# from datasets import Dataset, DatasetInfo, Value\n",
    "# from datasets.builder import ArrowBasedBuilder\n",
    "\n",
    "# class CustomDatasetBuilder(ArrowBasedBuilder):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "\n",
    "#     def _info(self):\n",
    "#         features = {\n",
    "#             \"last_hidden_state_of_last_token\": Value('float32'),\n",
    "#             \"label\": Value('int32')\n",
    "#         }\n",
    "#         return DatasetInfo(\n",
    "#             features=features,\n",
    "#         )\n",
    "\n",
    "#     def _split_generators(self, dl_manager):\n",
    "#         return [\n",
    "#             self._split_generation(split_name='train', file_path=self.config.data_files['train']),\n",
    "#             self._split_generation(split_name='validation', file_path=self.config.data_files['validation']),\n",
    "#             self._split_generation(split_name='test', file_path=self.config.data_files['test'])\n",
    "#         ]\n",
    "\n",
    "#     def _split_generation(self, split_name, file_path):\n",
    "#         return self._generate_examples(file_path)\n",
    "\n",
    "#     def _generate_examples(self, file_path):\n",
    "#         # Load your data from file or database\n",
    "#         # For simplicity, let's assume data is a list of dictionaries\n",
    "#         data = load_data(file_path)\n",
    "\n",
    "#         # Yield individual examples\n",
    "#         for idx, example in enumerate(data):\n",
    "#             yield idx, {\n",
    "#                 \"last_hidden_state_of_last_token\": example['last_hidden_state_of_last_token'],\n",
    "#                 \"label\": example['label']\n",
    "#             }\n",
    "\n",
    "\n",
    "def convert_to_custom_dataset_for_classifier(model, dataset):\n",
    "    # data_points = []\n",
    "    data_points = {\n",
    "        'last_hidden_state_of_last_token': [],\n",
    "        'label': []\n",
    "    }\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        # Assuming you extract x and y from each item\n",
    "        last_hidden_state_of_last_token = get_last_hidden_state_of_last_token(model, dataset[i][\"input_ids\"])\n",
    "        label = 0 if dataset[i]['output'] == 'NEUTRAL' else 1\n",
    "        data_points['last_hidden_state_of_last_token'].append(last_hidden_state_of_last_token)\n",
    "        data_points['label'].append(label)\n",
    "    return CustomDataset(data_points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_or_finetuned = \"finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [02:30<00:00,  5.99it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset_classifier = convert_to_custom_dataset_for_classifier(model, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  6.10it/s]\n"
     ]
    }
   ],
   "source": [
    "val_dataset_classifier = convert_to_custom_dataset_for_classifier(model, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Combine train_dataset and val_dataset into a DatasetDict\n",
    "dataset_dict_classifier = DatasetDict({\"train\": train_dataset_classifier, \"val\": val_dataset_classifier})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_training_dataset_dict_path = os.path.join(OUTPUT_DIR, f\"{model_name}={base_or_finetuned}={dataset_name}.dataset_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kokil/ahmad/benchmarking_llms/projects/qlora_training/create_dataset_jsons_aadish/llama=finetuned=gab.dataset_dict'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_training_dataset_dict_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_custom_dataset_dict_for_classifier(dataset_dict_classifier, classifier_training_dataset_dict_path):\n",
    "    torch.save(dataset_dict_classifier, classifier_training_dataset_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_custom_dataset_dict_for_classifier(classifier_training_dataset_dict_path):\n",
    "    dataset_dict_classifier = torch.load(classifier_training_dataset_dict_path)\n",
    "    return dataset_dict_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_custom_dataset_dict_for_classifier(dataset_dict_classifier, classifier_training_dataset_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "www = load_custom_dataset_dict_for_classifier(classifier_training_dataset_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "www == dataset_dict_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset(features=['last_hidden_state_of_last_token', 'label'], num_rows=900)\n",
       "    val: Dataset(features=['last_hidden_state_of_last_token', 'label'], num_rows=100)\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "www"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset(features=['last_hidden_state_of_last_token', 'label'], num_rows=900)\n",
       "    val: Dataset(features=['last_hidden_state_of_last_token', 'label'], num_rows=100)\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True\n",
      "0 True\n",
      "1 True\n",
      "1 True\n",
      "2 True\n",
      "2 True\n",
      "3 True\n",
      "3 True\n",
      "4 True\n",
      "4 True\n",
      "5 True\n",
      "5 True\n",
      "6 True\n",
      "6 True\n",
      "7 True\n",
      "7 True\n",
      "8 True\n",
      "8 True\n",
      "9 True\n",
      "9 True\n",
      "10 True\n",
      "10 True\n",
      "11 True\n",
      "11 True\n",
      "12 True\n",
      "12 True\n",
      "13 True\n",
      "13 True\n",
      "14 True\n",
      "14 True\n",
      "15 True\n",
      "15 True\n",
      "16 True\n",
      "16 True\n",
      "17 True\n",
      "17 True\n",
      "18 True\n",
      "18 True\n",
      "19 True\n",
      "19 True\n",
      "20 True\n",
      "20 True\n",
      "21 True\n",
      "21 True\n",
      "22 True\n",
      "22 True\n",
      "23 True\n",
      "23 True\n",
      "24 True\n",
      "24 True\n",
      "25 True\n",
      "25 True\n",
      "26 True\n",
      "26 True\n",
      "27 True\n",
      "27 True\n",
      "28 True\n",
      "28 True\n",
      "29 True\n",
      "29 True\n",
      "30 True\n",
      "30 True\n",
      "31 True\n",
      "31 True\n",
      "32 True\n",
      "32 True\n",
      "33 True\n",
      "33 True\n",
      "34 True\n",
      "34 True\n",
      "35 True\n",
      "35 True\n",
      "36 True\n",
      "36 True\n",
      "37 True\n",
      "37 True\n",
      "38 True\n",
      "38 True\n",
      "39 True\n",
      "39 True\n",
      "40 True\n",
      "40 True\n",
      "41 True\n",
      "41 True\n",
      "42 True\n",
      "42 True\n",
      "43 True\n",
      "43 True\n",
      "44 True\n",
      "44 True\n",
      "45 True\n",
      "45 True\n",
      "46 True\n",
      "46 True\n",
      "47 True\n",
      "47 True\n",
      "48 True\n",
      "48 True\n",
      "49 True\n",
      "49 True\n",
      "50 True\n",
      "50 True\n",
      "51 True\n",
      "51 True\n",
      "52 True\n",
      "52 True\n",
      "53 True\n",
      "53 True\n",
      "54 True\n",
      "54 True\n",
      "55 True\n",
      "55 True\n",
      "56 True\n",
      "56 True\n",
      "57 True\n",
      "57 True\n",
      "58 True\n",
      "58 True\n",
      "59 True\n",
      "59 True\n",
      "60 True\n",
      "60 True\n",
      "61 True\n",
      "61 True\n",
      "62 True\n",
      "62 True\n",
      "63 True\n",
      "63 True\n",
      "64 True\n",
      "64 True\n",
      "65 True\n",
      "65 True\n",
      "66 True\n",
      "66 True\n",
      "67 True\n",
      "67 True\n",
      "68 True\n",
      "68 True\n",
      "69 True\n",
      "69 True\n",
      "70 True\n",
      "70 True\n",
      "71 True\n",
      "71 True\n",
      "72 True\n",
      "72 True\n",
      "73 True\n",
      "73 True\n",
      "74 True\n",
      "74 True\n",
      "75 True\n",
      "75 True\n",
      "76 True\n",
      "76 True\n",
      "77 True\n",
      "77 True\n",
      "78 True\n",
      "78 True\n",
      "79 True\n",
      "79 True\n",
      "80 True\n",
      "80 True\n",
      "81 True\n",
      "81 True\n",
      "82 True\n",
      "82 True\n",
      "83 True\n",
      "83 True\n",
      "84 True\n",
      "84 True\n",
      "85 True\n",
      "85 True\n",
      "86 True\n",
      "86 True\n",
      "87 True\n",
      "87 True\n",
      "88 True\n",
      "88 True\n",
      "89 True\n",
      "89 True\n",
      "90 True\n",
      "90 True\n",
      "91 True\n",
      "91 True\n",
      "92 True\n",
      "92 True\n",
      "93 True\n",
      "93 True\n",
      "94 True\n",
      "94 True\n",
      "95 True\n",
      "95 True\n",
      "96 True\n",
      "96 True\n",
      "97 True\n",
      "97 True\n",
      "98 True\n",
      "98 True\n",
      "99 True\n",
      "99 True\n",
      "100 True\n",
      "100 True\n",
      "101 True\n",
      "101 True\n",
      "102 True\n",
      "102 True\n",
      "103 True\n",
      "103 True\n",
      "104 True\n",
      "104 True\n",
      "105 True\n",
      "105 True\n",
      "106 True\n",
      "106 True\n",
      "107 True\n",
      "107 True\n",
      "108 True\n",
      "108 True\n",
      "109 True\n",
      "109 True\n",
      "110 True\n",
      "110 True\n",
      "111 True\n",
      "111 True\n",
      "112 True\n",
      "112 True\n",
      "113 True\n",
      "113 True\n",
      "114 True\n",
      "114 True\n",
      "115 True\n",
      "115 True\n",
      "116 True\n",
      "116 True\n",
      "117 True\n",
      "117 True\n",
      "118 True\n",
      "118 True\n",
      "119 True\n",
      "119 True\n",
      "120 True\n",
      "120 True\n",
      "121 True\n",
      "121 True\n",
      "122 True\n",
      "122 True\n",
      "123 True\n",
      "123 True\n",
      "124 True\n",
      "124 True\n",
      "125 True\n",
      "125 True\n",
      "126 True\n",
      "126 True\n",
      "127 True\n",
      "127 True\n",
      "128 True\n",
      "128 True\n",
      "129 True\n",
      "129 True\n",
      "130 True\n",
      "130 True\n",
      "131 True\n",
      "131 True\n",
      "132 True\n",
      "132 True\n",
      "133 True\n",
      "133 True\n",
      "134 True\n",
      "134 True\n",
      "135 True\n",
      "135 True\n",
      "136 True\n",
      "136 True\n",
      "137 True\n",
      "137 True\n",
      "138 True\n",
      "138 True\n",
      "139 True\n",
      "139 True\n",
      "140 True\n",
      "140 True\n",
      "141 True\n",
      "141 True\n",
      "142 True\n",
      "142 True\n",
      "143 True\n",
      "143 True\n",
      "144 True\n",
      "144 True\n",
      "145 True\n",
      "145 True\n",
      "146 True\n",
      "146 True\n",
      "147 True\n",
      "147 True\n",
      "148 True\n",
      "148 True\n",
      "149 True\n",
      "149 True\n",
      "150 True\n",
      "150 True\n",
      "151 True\n",
      "151 True\n",
      "152 True\n",
      "152 True\n",
      "153 True\n",
      "153 True\n",
      "154 True\n",
      "154 True\n",
      "155 True\n",
      "155 True\n",
      "156 True\n",
      "156 True\n",
      "157 True\n",
      "157 True\n",
      "158 True\n",
      "158 True\n",
      "159 True\n",
      "159 True\n",
      "160 True\n",
      "160 True\n",
      "161 True\n",
      "161 True\n",
      "162 True\n",
      "162 True\n",
      "163 True\n",
      "163 True\n",
      "164 True\n",
      "164 True\n",
      "165 True\n",
      "165 True\n",
      "166 True\n",
      "166 True\n",
      "167 True\n",
      "167 True\n",
      "168 True\n",
      "168 True\n",
      "169 True\n",
      "169 True\n",
      "170 True\n",
      "170 True\n",
      "171 True\n",
      "171 True\n",
      "172 True\n",
      "172 True\n",
      "173 True\n",
      "173 True\n",
      "174 True\n",
      "174 True\n",
      "175 True\n",
      "175 True\n",
      "176 True\n",
      "176 True\n",
      "177 True\n",
      "177 True\n",
      "178 True\n",
      "178 True\n",
      "179 True\n",
      "179 True\n",
      "180 True\n",
      "180 True\n",
      "181 True\n",
      "181 True\n",
      "182 True\n",
      "182 True\n",
      "183 True\n",
      "183 True\n",
      "184 True\n",
      "184 True\n",
      "185 True\n",
      "185 True\n",
      "186 True\n",
      "186 True\n",
      "187 True\n",
      "187 True\n",
      "188 True\n",
      "188 True\n",
      "189 True\n",
      "189 True\n",
      "190 True\n",
      "190 True\n",
      "191 True\n",
      "191 True\n",
      "192 True\n",
      "192 True\n",
      "193 True\n",
      "193 True\n",
      "194 True\n",
      "194 True\n",
      "195 True\n",
      "195 True\n",
      "196 True\n",
      "196 True\n",
      "197 True\n",
      "197 True\n",
      "198 True\n",
      "198 True\n",
      "199 True\n",
      "199 True\n",
      "200 True\n",
      "200 True\n",
      "201 True\n",
      "201 True\n",
      "202 True\n",
      "202 True\n",
      "203 True\n",
      "203 True\n",
      "204 True\n",
      "204 True\n",
      "205 True\n",
      "205 True\n",
      "206 True\n",
      "206 True\n",
      "207 True\n",
      "207 True\n",
      "208 True\n",
      "208 True\n",
      "209 True\n",
      "209 True\n",
      "210 True\n",
      "210 True\n",
      "211 True\n",
      "211 True\n",
      "212 True\n",
      "212 True\n",
      "213 True\n",
      "213 True\n",
      "214 True\n",
      "214 True\n",
      "215 True\n",
      "215 True\n",
      "216 True\n",
      "216 True\n",
      "217 True\n",
      "217 True\n",
      "218 True\n",
      "218 True\n",
      "219 True\n",
      "219 True\n",
      "220 True\n",
      "220 True\n",
      "221 True\n",
      "221 True\n",
      "222 True\n",
      "222 True\n",
      "223 True\n",
      "223 True\n",
      "224 True\n",
      "224 True\n",
      "225 True\n",
      "225 True\n",
      "226 True\n",
      "226 True\n",
      "227 True\n",
      "227 True\n",
      "228 True\n",
      "228 True\n",
      "229 True\n",
      "229 True\n",
      "230 True\n",
      "230 True\n",
      "231 True\n",
      "231 True\n",
      "232 True\n",
      "232 True\n",
      "233 True\n",
      "233 True\n",
      "234 True\n",
      "234 True\n",
      "235 True\n",
      "235 True\n",
      "236 True\n",
      "236 True\n",
      "237 True\n",
      "237 True\n",
      "238 True\n",
      "238 True\n",
      "239 True\n",
      "239 True\n",
      "240 True\n",
      "240 True\n",
      "241 True\n",
      "241 True\n",
      "242 True\n",
      "242 True\n",
      "243 True\n",
      "243 True\n",
      "244 True\n",
      "244 True\n",
      "245 True\n",
      "245 True\n",
      "246 True\n",
      "246 True\n",
      "247 True\n",
      "247 True\n",
      "248 True\n",
      "248 True\n",
      "249 True\n",
      "249 True\n",
      "250 True\n",
      "250 True\n",
      "251 True\n",
      "251 True\n",
      "252 True\n",
      "252 True\n",
      "253 True\n",
      "253 True\n",
      "254 True\n",
      "254 True\n",
      "255 True\n",
      "255 True\n",
      "256 True\n",
      "256 True\n",
      "257 True\n",
      "257 True\n",
      "258 True\n",
      "258 True\n",
      "259 True\n",
      "259 True\n",
      "260 True\n",
      "260 True\n",
      "261 True\n",
      "261 True\n",
      "262 True\n",
      "262 True\n",
      "263 True\n",
      "263 True\n",
      "264 True\n",
      "264 True\n",
      "265 True\n",
      "265 True\n",
      "266 True\n",
      "266 True\n",
      "267 True\n",
      "267 True\n",
      "268 True\n",
      "268 True\n",
      "269 True\n",
      "269 True\n",
      "270 True\n",
      "270 True\n",
      "271 True\n",
      "271 True\n",
      "272 True\n",
      "272 True\n",
      "273 True\n",
      "273 True\n",
      "274 True\n",
      "274 True\n",
      "275 True\n",
      "275 True\n",
      "276 True\n",
      "276 True\n",
      "277 True\n",
      "277 True\n",
      "278 True\n",
      "278 True\n",
      "279 True\n",
      "279 True\n",
      "280 True\n",
      "280 True\n",
      "281 True\n",
      "281 True\n",
      "282 True\n",
      "282 True\n",
      "283 True\n",
      "283 True\n",
      "284 True\n",
      "284 True\n",
      "285 True\n",
      "285 True\n",
      "286 True\n",
      "286 True\n",
      "287 True\n",
      "287 True\n",
      "288 True\n",
      "288 True\n",
      "289 True\n",
      "289 True\n",
      "290 True\n",
      "290 True\n",
      "291 True\n",
      "291 True\n",
      "292 True\n",
      "292 True\n",
      "293 True\n",
      "293 True\n",
      "294 True\n",
      "294 True\n",
      "295 True\n",
      "295 True\n",
      "296 True\n",
      "296 True\n",
      "297 True\n",
      "297 True\n",
      "298 True\n",
      "298 True\n",
      "299 True\n",
      "299 True\n",
      "300 True\n",
      "300 True\n",
      "301 True\n",
      "301 True\n",
      "302 True\n",
      "302 True\n",
      "303 True\n",
      "303 True\n",
      "304 True\n",
      "304 True\n",
      "305 True\n",
      "305 True\n",
      "306 True\n",
      "306 True\n",
      "307 True\n",
      "307 True\n",
      "308 True\n",
      "308 True\n",
      "309 True\n",
      "309 True\n",
      "310 True\n",
      "310 True\n",
      "311 True\n",
      "311 True\n",
      "312 True\n",
      "312 True\n",
      "313 True\n",
      "313 True\n",
      "314 True\n",
      "314 True\n",
      "315 True\n",
      "315 True\n",
      "316 True\n",
      "316 True\n",
      "317 True\n",
      "317 True\n",
      "318 True\n",
      "318 True\n",
      "319 True\n",
      "319 True\n",
      "320 True\n",
      "320 True\n",
      "321 True\n",
      "321 True\n",
      "322 True\n",
      "322 True\n",
      "323 True\n",
      "323 True\n",
      "324 True\n",
      "324 True\n",
      "325 True\n",
      "325 True\n",
      "326 True\n",
      "326 True\n",
      "327 True\n",
      "327 True\n",
      "328 True\n",
      "328 True\n",
      "329 True\n",
      "329 True\n",
      "330 True\n",
      "330 True\n",
      "331 True\n",
      "331 True\n",
      "332 True\n",
      "332 True\n",
      "333 True\n",
      "333 True\n",
      "334 True\n",
      "334 True\n",
      "335 True\n",
      "335 True\n",
      "336 True\n",
      "336 True\n",
      "337 True\n",
      "337 True\n",
      "338 True\n",
      "338 True\n",
      "339 True\n",
      "339 True\n",
      "340 True\n",
      "340 True\n",
      "341 True\n",
      "341 True\n",
      "342 True\n",
      "342 True\n",
      "343 True\n",
      "343 True\n",
      "344 True\n",
      "344 True\n",
      "345 True\n",
      "345 True\n",
      "346 True\n",
      "346 True\n",
      "347 True\n",
      "347 True\n",
      "348 True\n",
      "348 True\n",
      "349 True\n",
      "349 True\n",
      "350 True\n",
      "350 True\n",
      "351 True\n",
      "351 True\n",
      "352 True\n",
      "352 True\n",
      "353 True\n",
      "353 True\n",
      "354 True\n",
      "354 True\n",
      "355 True\n",
      "355 True\n",
      "356 True\n",
      "356 True\n",
      "357 True\n",
      "357 True\n",
      "358 True\n",
      "358 True\n",
      "359 True\n",
      "359 True\n",
      "360 True\n",
      "360 True\n",
      "361 True\n",
      "361 True\n",
      "362 True\n",
      "362 True\n",
      "363 True\n",
      "363 True\n",
      "364 True\n",
      "364 True\n",
      "365 True\n",
      "365 True\n",
      "366 True\n",
      "366 True\n",
      "367 True\n",
      "367 True\n",
      "368 True\n",
      "368 True\n",
      "369 True\n",
      "369 True\n",
      "370 True\n",
      "370 True\n",
      "371 True\n",
      "371 True\n",
      "372 True\n",
      "372 True\n",
      "373 True\n",
      "373 True\n",
      "374 True\n",
      "374 True\n",
      "375 True\n",
      "375 True\n",
      "376 True\n",
      "376 True\n",
      "377 True\n",
      "377 True\n",
      "378 True\n",
      "378 True\n",
      "379 True\n",
      "379 True\n",
      "380 True\n",
      "380 True\n",
      "381 True\n",
      "381 True\n",
      "382 True\n",
      "382 True\n",
      "383 True\n",
      "383 True\n",
      "384 True\n",
      "384 True\n",
      "385 True\n",
      "385 True\n",
      "386 True\n",
      "386 True\n",
      "387 True\n",
      "387 True\n",
      "388 True\n",
      "388 True\n",
      "389 True\n",
      "389 True\n",
      "390 True\n",
      "390 True\n",
      "391 True\n",
      "391 True\n",
      "392 True\n",
      "392 True\n",
      "393 True\n",
      "393 True\n",
      "394 True\n",
      "394 True\n",
      "395 True\n",
      "395 True\n",
      "396 True\n",
      "396 True\n",
      "397 True\n",
      "397 True\n",
      "398 True\n",
      "398 True\n",
      "399 True\n",
      "399 True\n",
      "400 True\n",
      "400 True\n",
      "401 True\n",
      "401 True\n",
      "402 True\n",
      "402 True\n",
      "403 True\n",
      "403 True\n",
      "404 True\n",
      "404 True\n",
      "405 True\n",
      "405 True\n",
      "406 True\n",
      "406 True\n",
      "407 True\n",
      "407 True\n",
      "408 True\n",
      "408 True\n",
      "409 True\n",
      "409 True\n",
      "410 True\n",
      "410 True\n",
      "411 True\n",
      "411 True\n",
      "412 True\n",
      "412 True\n",
      "413 True\n",
      "413 True\n",
      "414 True\n",
      "414 True\n",
      "415 True\n",
      "415 True\n",
      "416 True\n",
      "416 True\n",
      "417 True\n",
      "417 True\n",
      "418 True\n",
      "418 True\n",
      "419 True\n",
      "419 True\n",
      "420 True\n",
      "420 True\n",
      "421 True\n",
      "421 True\n",
      "422 True\n",
      "422 True\n",
      "423 True\n",
      "423 True\n",
      "424 True\n",
      "424 True\n",
      "425 True\n",
      "425 True\n",
      "426 True\n",
      "426 True\n",
      "427 True\n",
      "427 True\n",
      "428 True\n",
      "428 True\n",
      "429 True\n",
      "429 True\n",
      "430 True\n",
      "430 True\n",
      "431 True\n",
      "431 True\n",
      "432 True\n",
      "432 True\n",
      "433 True\n",
      "433 True\n",
      "434 True\n",
      "434 True\n",
      "435 True\n",
      "435 True\n",
      "436 True\n",
      "436 True\n",
      "437 True\n",
      "437 True\n",
      "438 True\n",
      "438 True\n",
      "439 True\n",
      "439 True\n",
      "440 True\n",
      "440 True\n",
      "441 True\n",
      "441 True\n",
      "442 True\n",
      "442 True\n",
      "443 True\n",
      "443 True\n",
      "444 True\n",
      "444 True\n",
      "445 True\n",
      "445 True\n",
      "446 True\n",
      "446 True\n",
      "447 True\n",
      "447 True\n",
      "448 True\n",
      "448 True\n",
      "449 True\n",
      "449 True\n",
      "450 True\n",
      "450 True\n",
      "451 True\n",
      "451 True\n",
      "452 True\n",
      "452 True\n",
      "453 True\n",
      "453 True\n",
      "454 True\n",
      "454 True\n",
      "455 True\n",
      "455 True\n",
      "456 True\n",
      "456 True\n",
      "457 True\n",
      "457 True\n",
      "458 True\n",
      "458 True\n",
      "459 True\n",
      "459 True\n",
      "460 True\n",
      "460 True\n",
      "461 True\n",
      "461 True\n",
      "462 True\n",
      "462 True\n",
      "463 True\n",
      "463 True\n",
      "464 True\n",
      "464 True\n",
      "465 True\n",
      "465 True\n",
      "466 True\n",
      "466 True\n",
      "467 True\n",
      "467 True\n",
      "468 True\n",
      "468 True\n",
      "469 True\n",
      "469 True\n",
      "470 True\n",
      "470 True\n",
      "471 True\n",
      "471 True\n",
      "472 True\n",
      "472 True\n",
      "473 True\n",
      "473 True\n",
      "474 True\n",
      "474 True\n",
      "475 True\n",
      "475 True\n",
      "476 True\n",
      "476 True\n",
      "477 True\n",
      "477 True\n",
      "478 True\n",
      "478 True\n",
      "479 True\n",
      "479 True\n",
      "480 True\n",
      "480 True\n",
      "481 True\n",
      "481 True\n",
      "482 True\n",
      "482 True\n",
      "483 True\n",
      "483 True\n",
      "484 True\n",
      "484 True\n",
      "485 True\n",
      "485 True\n",
      "486 True\n",
      "486 True\n",
      "487 True\n",
      "487 True\n",
      "488 True\n",
      "488 True\n",
      "489 True\n",
      "489 True\n",
      "490 True\n",
      "490 True\n",
      "491 True\n",
      "491 True\n",
      "492 True\n",
      "492 True\n",
      "493 True\n",
      "493 True\n",
      "494 True\n",
      "494 True\n",
      "495 True\n",
      "495 True\n",
      "496 True\n",
      "496 True\n",
      "497 True\n",
      "497 True\n",
      "498 True\n",
      "498 True\n",
      "499 True\n",
      "499 True\n",
      "500 True\n",
      "500 True\n",
      "501 True\n",
      "501 True\n",
      "502 True\n",
      "502 True\n",
      "503 True\n",
      "503 True\n",
      "504 True\n",
      "504 True\n",
      "505 True\n",
      "505 True\n",
      "506 True\n",
      "506 True\n",
      "507 True\n",
      "507 True\n",
      "508 True\n",
      "508 True\n",
      "509 True\n",
      "509 True\n",
      "510 True\n",
      "510 True\n",
      "511 True\n",
      "511 True\n",
      "512 True\n",
      "512 True\n",
      "513 True\n",
      "513 True\n",
      "514 True\n",
      "514 True\n",
      "515 True\n",
      "515 True\n",
      "516 True\n",
      "516 True\n",
      "517 True\n",
      "517 True\n",
      "518 True\n",
      "518 True\n",
      "519 True\n",
      "519 True\n",
      "520 True\n",
      "520 True\n",
      "521 True\n",
      "521 True\n",
      "522 True\n",
      "522 True\n",
      "523 True\n",
      "523 True\n",
      "524 True\n",
      "524 True\n",
      "525 True\n",
      "525 True\n",
      "526 True\n",
      "526 True\n",
      "527 True\n",
      "527 True\n",
      "528 True\n",
      "528 True\n",
      "529 True\n",
      "529 True\n",
      "530 True\n",
      "530 True\n",
      "531 True\n",
      "531 True\n",
      "532 True\n",
      "532 True\n",
      "533 True\n",
      "533 True\n",
      "534 True\n",
      "534 True\n",
      "535 True\n",
      "535 True\n",
      "536 True\n",
      "536 True\n",
      "537 True\n",
      "537 True\n",
      "538 True\n",
      "538 True\n",
      "539 True\n",
      "539 True\n",
      "540 True\n",
      "540 True\n",
      "541 True\n",
      "541 True\n",
      "542 True\n",
      "542 True\n",
      "543 True\n",
      "543 True\n",
      "544 True\n",
      "544 True\n",
      "545 True\n",
      "545 True\n",
      "546 True\n",
      "546 True\n",
      "547 True\n",
      "547 True\n",
      "548 True\n",
      "548 True\n",
      "549 True\n",
      "549 True\n",
      "550 True\n",
      "550 True\n",
      "551 True\n",
      "551 True\n",
      "552 True\n",
      "552 True\n",
      "553 True\n",
      "553 True\n",
      "554 True\n",
      "554 True\n",
      "555 True\n",
      "555 True\n",
      "556 True\n",
      "556 True\n",
      "557 True\n",
      "557 True\n",
      "558 True\n",
      "558 True\n",
      "559 True\n",
      "559 True\n",
      "560 True\n",
      "560 True\n",
      "561 True\n",
      "561 True\n",
      "562 True\n",
      "562 True\n",
      "563 True\n",
      "563 True\n",
      "564 True\n",
      "564 True\n",
      "565 True\n",
      "565 True\n",
      "566 True\n",
      "566 True\n",
      "567 True\n",
      "567 True\n",
      "568 True\n",
      "568 True\n",
      "569 True\n",
      "569 True\n",
      "570 True\n",
      "570 True\n",
      "571 True\n",
      "571 True\n",
      "572 True\n",
      "572 True\n",
      "573 True\n",
      "573 True\n",
      "574 True\n",
      "574 True\n",
      "575 True\n",
      "575 True\n",
      "576 True\n",
      "576 True\n",
      "577 True\n",
      "577 True\n",
      "578 True\n",
      "578 True\n",
      "579 True\n",
      "579 True\n",
      "580 True\n",
      "580 True\n",
      "581 True\n",
      "581 True\n",
      "582 True\n",
      "582 True\n",
      "583 True\n",
      "583 True\n",
      "584 True\n",
      "584 True\n",
      "585 True\n",
      "585 True\n",
      "586 True\n",
      "586 True\n",
      "587 True\n",
      "587 True\n",
      "588 True\n",
      "588 True\n",
      "589 True\n",
      "589 True\n",
      "590 True\n",
      "590 True\n",
      "591 True\n",
      "591 True\n",
      "592 True\n",
      "592 True\n",
      "593 True\n",
      "593 True\n",
      "594 True\n",
      "594 True\n",
      "595 True\n",
      "595 True\n",
      "596 True\n",
      "596 True\n",
      "597 True\n",
      "597 True\n",
      "598 True\n",
      "598 True\n",
      "599 True\n",
      "599 True\n",
      "600 True\n",
      "600 True\n",
      "601 True\n",
      "601 True\n",
      "602 True\n",
      "602 True\n",
      "603 True\n",
      "603 True\n",
      "604 True\n",
      "604 True\n",
      "605 True\n",
      "605 True\n",
      "606 True\n",
      "606 True\n",
      "607 True\n",
      "607 True\n",
      "608 True\n",
      "608 True\n",
      "609 True\n",
      "609 True\n",
      "610 True\n",
      "610 True\n",
      "611 True\n",
      "611 True\n",
      "612 True\n",
      "612 True\n",
      "613 True\n",
      "613 True\n",
      "614 True\n",
      "614 True\n",
      "615 True\n",
      "615 True\n",
      "616 True\n",
      "616 True\n",
      "617 True\n",
      "617 True\n",
      "618 True\n",
      "618 True\n",
      "619 True\n",
      "619 True\n",
      "620 True\n",
      "620 True\n",
      "621 True\n",
      "621 True\n",
      "622 True\n",
      "622 True\n",
      "623 True\n",
      "623 True\n",
      "624 True\n",
      "624 True\n",
      "625 True\n",
      "625 True\n",
      "626 True\n",
      "626 True\n",
      "627 True\n",
      "627 True\n",
      "628 True\n",
      "628 True\n",
      "629 True\n",
      "629 True\n",
      "630 True\n",
      "630 True\n",
      "631 True\n",
      "631 True\n",
      "632 True\n",
      "632 True\n",
      "633 True\n",
      "633 True\n",
      "634 True\n",
      "634 True\n",
      "635 True\n",
      "635 True\n",
      "636 True\n",
      "636 True\n",
      "637 True\n",
      "637 True\n",
      "638 True\n",
      "638 True\n",
      "639 True\n",
      "639 True\n",
      "640 True\n",
      "640 True\n",
      "641 True\n",
      "641 True\n",
      "642 True\n",
      "642 True\n",
      "643 True\n",
      "643 True\n",
      "644 True\n",
      "644 True\n",
      "645 True\n",
      "645 True\n",
      "646 True\n",
      "646 True\n",
      "647 True\n",
      "647 True\n",
      "648 True\n",
      "648 True\n",
      "649 True\n",
      "649 True\n",
      "650 True\n",
      "650 True\n",
      "651 True\n",
      "651 True\n",
      "652 True\n",
      "652 True\n",
      "653 True\n",
      "653 True\n",
      "654 True\n",
      "654 True\n",
      "655 True\n",
      "655 True\n",
      "656 True\n",
      "656 True\n",
      "657 True\n",
      "657 True\n",
      "658 True\n",
      "658 True\n",
      "659 True\n",
      "659 True\n",
      "660 True\n",
      "660 True\n",
      "661 True\n",
      "661 True\n",
      "662 True\n",
      "662 True\n",
      "663 True\n",
      "663 True\n",
      "664 True\n",
      "664 True\n",
      "665 True\n",
      "665 True\n",
      "666 True\n",
      "666 True\n",
      "667 True\n",
      "667 True\n",
      "668 True\n",
      "668 True\n",
      "669 True\n",
      "669 True\n",
      "670 True\n",
      "670 True\n",
      "671 True\n",
      "671 True\n",
      "672 True\n",
      "672 True\n",
      "673 True\n",
      "673 True\n",
      "674 True\n",
      "674 True\n",
      "675 True\n",
      "675 True\n",
      "676 True\n",
      "676 True\n",
      "677 True\n",
      "677 True\n",
      "678 True\n",
      "678 True\n",
      "679 True\n",
      "679 True\n",
      "680 True\n",
      "680 True\n",
      "681 True\n",
      "681 True\n",
      "682 True\n",
      "682 True\n",
      "683 True\n",
      "683 True\n",
      "684 True\n",
      "684 True\n",
      "685 True\n",
      "685 True\n",
      "686 True\n",
      "686 True\n",
      "687 True\n",
      "687 True\n",
      "688 True\n",
      "688 True\n",
      "689 True\n",
      "689 True\n",
      "690 True\n",
      "690 True\n",
      "691 True\n",
      "691 True\n",
      "692 True\n",
      "692 True\n",
      "693 True\n",
      "693 True\n",
      "694 True\n",
      "694 True\n",
      "695 True\n",
      "695 True\n",
      "696 True\n",
      "696 True\n",
      "697 True\n",
      "697 True\n",
      "698 True\n",
      "698 True\n",
      "699 True\n",
      "699 True\n",
      "700 True\n",
      "700 True\n",
      "701 True\n",
      "701 True\n",
      "702 True\n",
      "702 True\n",
      "703 True\n",
      "703 True\n",
      "704 True\n",
      "704 True\n",
      "705 True\n",
      "705 True\n",
      "706 True\n",
      "706 True\n",
      "707 True\n",
      "707 True\n",
      "708 True\n",
      "708 True\n",
      "709 True\n",
      "709 True\n",
      "710 True\n",
      "710 True\n",
      "711 True\n",
      "711 True\n",
      "712 True\n",
      "712 True\n",
      "713 True\n",
      "713 True\n",
      "714 True\n",
      "714 True\n",
      "715 True\n",
      "715 True\n",
      "716 True\n",
      "716 True\n",
      "717 True\n",
      "717 True\n",
      "718 True\n",
      "718 True\n",
      "719 True\n",
      "719 True\n",
      "720 True\n",
      "720 True\n",
      "721 True\n",
      "721 True\n",
      "722 True\n",
      "722 True\n",
      "723 True\n",
      "723 True\n",
      "724 True\n",
      "724 True\n",
      "725 True\n",
      "725 True\n",
      "726 True\n",
      "726 True\n",
      "727 True\n",
      "727 True\n",
      "728 True\n",
      "728 True\n",
      "729 True\n",
      "729 True\n",
      "730 True\n",
      "730 True\n",
      "731 True\n",
      "731 True\n",
      "732 True\n",
      "732 True\n",
      "733 True\n",
      "733 True\n",
      "734 True\n",
      "734 True\n",
      "735 True\n",
      "735 True\n",
      "736 True\n",
      "736 True\n",
      "737 True\n",
      "737 True\n",
      "738 True\n",
      "738 True\n",
      "739 True\n",
      "739 True\n",
      "740 True\n",
      "740 True\n",
      "741 True\n",
      "741 True\n",
      "742 True\n",
      "742 True\n",
      "743 True\n",
      "743 True\n",
      "744 True\n",
      "744 True\n",
      "745 True\n",
      "745 True\n",
      "746 True\n",
      "746 True\n",
      "747 True\n",
      "747 True\n",
      "748 True\n",
      "748 True\n",
      "749 True\n",
      "749 True\n",
      "750 True\n",
      "750 True\n",
      "751 True\n",
      "751 True\n",
      "752 True\n",
      "752 True\n",
      "753 True\n",
      "753 True\n",
      "754 True\n",
      "754 True\n",
      "755 True\n",
      "755 True\n",
      "756 True\n",
      "756 True\n",
      "757 True\n",
      "757 True\n",
      "758 True\n",
      "758 True\n",
      "759 True\n",
      "759 True\n",
      "760 True\n",
      "760 True\n",
      "761 True\n",
      "761 True\n",
      "762 True\n",
      "762 True\n",
      "763 True\n",
      "763 True\n",
      "764 True\n",
      "764 True\n",
      "765 True\n",
      "765 True\n",
      "766 True\n",
      "766 True\n",
      "767 True\n",
      "767 True\n",
      "768 True\n",
      "768 True\n",
      "769 True\n",
      "769 True\n",
      "770 True\n",
      "770 True\n",
      "771 True\n",
      "771 True\n",
      "772 True\n",
      "772 True\n",
      "773 True\n",
      "773 True\n",
      "774 True\n",
      "774 True\n",
      "775 True\n",
      "775 True\n",
      "776 True\n",
      "776 True\n",
      "777 True\n",
      "777 True\n",
      "778 True\n",
      "778 True\n",
      "779 True\n",
      "779 True\n",
      "780 True\n",
      "780 True\n",
      "781 True\n",
      "781 True\n",
      "782 True\n",
      "782 True\n",
      "783 True\n",
      "783 True\n",
      "784 True\n",
      "784 True\n",
      "785 True\n",
      "785 True\n",
      "786 True\n",
      "786 True\n",
      "787 True\n",
      "787 True\n",
      "788 True\n",
      "788 True\n",
      "789 True\n",
      "789 True\n",
      "790 True\n",
      "790 True\n",
      "791 True\n",
      "791 True\n",
      "792 True\n",
      "792 True\n",
      "793 True\n",
      "793 True\n",
      "794 True\n",
      "794 True\n",
      "795 True\n",
      "795 True\n",
      "796 True\n",
      "796 True\n",
      "797 True\n",
      "797 True\n",
      "798 True\n",
      "798 True\n",
      "799 True\n",
      "799 True\n",
      "800 True\n",
      "800 True\n",
      "801 True\n",
      "801 True\n",
      "802 True\n",
      "802 True\n",
      "803 True\n",
      "803 True\n",
      "804 True\n",
      "804 True\n",
      "805 True\n",
      "805 True\n",
      "806 True\n",
      "806 True\n",
      "807 True\n",
      "807 True\n",
      "808 True\n",
      "808 True\n",
      "809 True\n",
      "809 True\n",
      "810 True\n",
      "810 True\n",
      "811 True\n",
      "811 True\n",
      "812 True\n",
      "812 True\n",
      "813 True\n",
      "813 True\n",
      "814 True\n",
      "814 True\n",
      "815 True\n",
      "815 True\n",
      "816 True\n",
      "816 True\n",
      "817 True\n",
      "817 True\n",
      "818 True\n",
      "818 True\n",
      "819 True\n",
      "819 True\n",
      "820 True\n",
      "820 True\n",
      "821 True\n",
      "821 True\n",
      "822 True\n",
      "822 True\n",
      "823 True\n",
      "823 True\n",
      "824 True\n",
      "824 True\n",
      "825 True\n",
      "825 True\n",
      "826 True\n",
      "826 True\n",
      "827 True\n",
      "827 True\n",
      "828 True\n",
      "828 True\n",
      "829 True\n",
      "829 True\n",
      "830 True\n",
      "830 True\n",
      "831 True\n",
      "831 True\n",
      "832 True\n",
      "832 True\n",
      "833 True\n",
      "833 True\n",
      "834 True\n",
      "834 True\n",
      "835 True\n",
      "835 True\n",
      "836 True\n",
      "836 True\n",
      "837 True\n",
      "837 True\n",
      "838 True\n",
      "838 True\n",
      "839 True\n",
      "839 True\n",
      "840 True\n",
      "840 True\n",
      "841 True\n",
      "841 True\n",
      "842 True\n",
      "842 True\n",
      "843 True\n",
      "843 True\n",
      "844 True\n",
      "844 True\n",
      "845 True\n",
      "845 True\n",
      "846 True\n",
      "846 True\n",
      "847 True\n",
      "847 True\n",
      "848 True\n",
      "848 True\n",
      "849 True\n",
      "849 True\n",
      "850 True\n",
      "850 True\n",
      "851 True\n",
      "851 True\n",
      "852 True\n",
      "852 True\n",
      "853 True\n",
      "853 True\n",
      "854 True\n",
      "854 True\n",
      "855 True\n",
      "855 True\n",
      "856 True\n",
      "856 True\n",
      "857 True\n",
      "857 True\n",
      "858 True\n",
      "858 True\n",
      "859 True\n",
      "859 True\n",
      "860 True\n",
      "860 True\n",
      "861 True\n",
      "861 True\n",
      "862 True\n",
      "862 True\n",
      "863 True\n",
      "863 True\n",
      "864 True\n",
      "864 True\n",
      "865 True\n",
      "865 True\n",
      "866 True\n",
      "866 True\n",
      "867 True\n",
      "867 True\n",
      "868 True\n",
      "868 True\n",
      "869 True\n",
      "869 True\n",
      "870 True\n",
      "870 True\n",
      "871 True\n",
      "871 True\n",
      "872 True\n",
      "872 True\n",
      "873 True\n",
      "873 True\n",
      "874 True\n",
      "874 True\n",
      "875 True\n",
      "875 True\n",
      "876 True\n",
      "876 True\n",
      "877 True\n",
      "877 True\n",
      "878 True\n",
      "878 True\n",
      "879 True\n",
      "879 True\n",
      "880 True\n",
      "880 True\n",
      "881 True\n",
      "881 True\n",
      "882 True\n",
      "882 True\n",
      "883 True\n",
      "883 True\n",
      "884 True\n",
      "884 True\n",
      "885 True\n",
      "885 True\n",
      "886 True\n",
      "886 True\n",
      "887 True\n",
      "887 True\n",
      "888 True\n",
      "888 True\n",
      "889 True\n",
      "889 True\n",
      "890 True\n",
      "890 True\n",
      "891 True\n",
      "891 True\n",
      "892 True\n",
      "892 True\n",
      "893 True\n",
      "893 True\n",
      "894 True\n",
      "894 True\n",
      "895 True\n",
      "895 True\n",
      "896 True\n",
      "896 True\n",
      "897 True\n",
      "897 True\n",
      "898 True\n",
      "898 True\n",
      "899 True\n",
      "899 True\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset_dict_classifier['train'])):\n",
    "    print(i, (dataset_dict_classifier['train'][i]['last_hidden_state_of_last_token'] == www['train'][i]['last_hidden_state_of_last_token']).all().item())\n",
    "    print(i, (dataset_dict_classifier['train'][i]['label'] == www['train'][i]['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict_classifier['train'][0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "www['train'][0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:11')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict_classifier['train'][0]['last_hidden_state_of_last_token'] == www['train'][0]['last_hidden_state_of_last_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7729, -1.4340,  0.3075,  ..., -0.5573,  0.0064, -0.7626],\n",
       "        [-2.1269, -1.0881,  0.1922,  ...,  0.5358, -1.3013, -0.1749],\n",
       "        [-3.6840,  0.4955, -0.6878,  ...,  0.9461,  0.0840,  0.6209],\n",
       "        ...,\n",
       "        [ 0.0925, -0.5180,  2.2729,  ...,  0.3876, -0.2024, -2.4149],\n",
       "        [-1.5827, -1.5720,  3.3173,  ...,  0.2413,  0.7279,  1.1369],\n",
       "        [ 1.3438, -1.2516,  3.3698,  ..., -0.2226, -2.2946, -1.2497]],\n",
       "       device='cuda:11')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "www['train'][0]['last_hidden_state_of_last_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_custom_dataset_for_classifier(dataset_classifier, ):\n",
    "#     CustomDataset(torch.load(f'{split_name}_dataset.pt'))\n",
    "#     # data_points =a {\n",
    "#     #     'last_hidden_state_of_last_token': [],\n",
    "#     #     'label': []\n",
    "#     # }\n",
    "#     # for data_point in dataset_classifier:\n",
    "#     #     data_points['last_hidden_state_of_last_token'].append(data_point['last_hidden_state_of_last_token'])\n",
    "#     #     data_points['label'].append(data_point['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_custom_dataset_for_classifier(dataset_classifier, ):\n",
    "#     data_points = {\n",
    "#         'last_hidden_state_of_last_token': [],\n",
    "#         'label': []\n",
    "#     }\n",
    "#     for data_point in dataset_classifier:\n",
    "#         data_points['last_hidden_state_of_last_token'].append(data_point['last_hidden_state_of_last_token'])\n",
    "#         data_points['label'].append(data_point['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_combined_dataset = DatasetDict({\n",
    "#     split_name: CustomDataset(torch.load(f'{split_name}_dataset.pt'))\n",
    "#     for split_name in ['train', 'val']\n",
    "# })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_training_dataset_output_home = \"classifier_training_dataset_output_home\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.path.join(classifier_training_dataset_output_home, model_name, base_or_finetuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classifier_training_dataset_output_home/llama/finetuned'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_training_dataset_dict_path = os.path.join(OUTPUT_DIR, f\"{model_name}={base_or_finetuned}={dataset_name}.dataset_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kokil/ahmad/benchmarking_llms/projects/qlora_training/create_dataset_jsons_aadish/llama=finetuned=gab.dataset_classifier'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_training_dataset_dict_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  6.11it/s]\n"
     ]
    }
   ],
   "source": [
    "val_dataset_classifier = convert_to_custom_dataset_for_classifier(model, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_decoder().layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 139])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zzz = model(input_ids, output_hidden_states=True)\n",
    "# zzz1 = model(input_ids, return_dict=True)\n",
    "# zzz2 = model(input_ids, output_hidden_states=True, return_dict=True)\n",
    "zzz3 = model.model(input_ids, output_hidden_states=True, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4096, out_features=32000, bias=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(\n",
       "            in_features=4096, out_features=4096, bias=False\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(\n",
       "            in_features=4096, out_features=4096, bias=False\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "zzz4 = model.get_decoder()(input_ids, output_hidden_states=True, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 139])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 139])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 139, 4096])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz4.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([139, 4096])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz4.last_hidden_state[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz4.last_hidden_state[0][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_hidden_state': tensor([[[ 1.7729, -1.4340,  0.3075,  ..., -0.5573,  0.0064, -0.7626],\n",
       "          [-2.1269, -1.0881,  0.1922,  ...,  0.5358, -1.3013, -0.1749],\n",
       "          [-3.6840,  0.4955, -0.6878,  ...,  0.9461,  0.0840,  0.6209],\n",
       "          ...,\n",
       "          [ 0.0925, -0.5180,  2.2729,  ...,  0.3876, -0.2024, -2.4149],\n",
       "          [-1.5827, -1.5720,  3.3173,  ...,  0.2413,  0.7279,  1.1369],\n",
       "          [ 1.3438, -1.2516,  3.3698,  ..., -0.2226, -2.2946, -1.2497]]],\n",
       "        device='cuda:11'),\n",
       " 'past_key_values': None,\n",
       " 'hidden_states': (tensor([[[ 9.8884e-05, -2.3329e-04,  5.8460e-04,  ..., -3.4237e-04,\n",
       "             5.9724e-05, -1.1957e-04],\n",
       "           [ 2.5040e-02,  5.5618e-03, -6.8588e-03,  ...,  3.5934e-03,\n",
       "            -2.4353e-02,  1.6769e-02],\n",
       "           [-1.2650e-02, -1.8097e-02, -8.9264e-03,  ..., -1.7061e-03,\n",
       "            -6.9504e-03,  1.1192e-02],\n",
       "           ...,\n",
       "           [-1.4565e-02, -2.0508e-02,  9.6035e-04,  ...,  3.5324e-03,\n",
       "            -4.6921e-03, -2.1000e-03],\n",
       "           [ 3.0112e-04, -8.2159e-04, -4.9829e-05,  ..., -1.3113e-05,\n",
       "            -1.3037e-03, -1.1778e-04],\n",
       "           [ 9.8884e-05, -2.3329e-04,  5.8460e-04,  ..., -3.4237e-04,\n",
       "             5.9724e-05, -1.1957e-04]]], device='cuda:0'),\n",
       "  tensor([[[ 0.0079, -0.0354, -0.0052,  ..., -0.0051,  0.0036,  0.0052],\n",
       "           [ 0.0698, -0.0084, -0.0377,  ..., -0.0147, -0.0902, -0.0141],\n",
       "           [-0.0426, -0.0515, -0.0315,  ..., -0.0406,  0.0116,  0.0092],\n",
       "           ...,\n",
       "           [-0.0161, -0.0310, -0.0231,  ..., -0.0117,  0.0089, -0.0010],\n",
       "           [ 0.0022, -0.0318,  0.0015,  ..., -0.0009,  0.0107, -0.0309],\n",
       "           [ 0.1018, -0.1963, -0.0079,  ...,  0.0937,  0.0454,  0.1366]]],\n",
       "         device='cuda:0'),\n",
       "  tensor([[[ 0.1429, -0.0047,  0.0479,  ...,  0.0029,  0.0319, -0.0771],\n",
       "           [ 0.0576,  0.0080,  0.0808,  ..., -0.0762, -0.2180, -0.1311],\n",
       "           [-0.0467, -0.0553, -0.0831,  ..., -0.0864, -0.0029,  0.0520],\n",
       "           ...,\n",
       "           [-0.0592, -0.0500, -0.0219,  ..., -0.0068,  0.0117,  0.0074],\n",
       "           [ 0.0166, -0.0323, -0.0178,  ...,  0.0041,  0.0087, -0.0207],\n",
       "           [ 0.0708, -0.1619,  0.0147,  ...,  0.1295,  0.0736,  0.1230]]],\n",
       "         device='cuda:1'),\n",
       "  tensor([[[-0.2274,  0.1281, -0.2564,  ..., -0.3940,  0.3321,  0.2670],\n",
       "           [-0.0665,  0.0598,  0.0456,  ..., -0.0569, -0.3154, -0.3044],\n",
       "           [-0.0257,  0.0221, -0.1017,  ..., -0.0782, -0.0312, -0.0554],\n",
       "           ...,\n",
       "           [-0.0450, -0.0259,  0.1025,  ..., -0.0265,  0.1031,  0.0209],\n",
       "           [-0.0210, -0.0567,  0.0008,  ..., -0.0244,  0.0550, -0.0177],\n",
       "           [ 0.0326, -0.1894,  0.0203,  ...,  0.1272,  0.0994,  0.1096]]],\n",
       "         device='cuda:1'),\n",
       "  tensor([[[-0.2455,  0.1307, -0.2658,  ..., -0.3586,  0.3662,  0.2564],\n",
       "           [ 0.1149,  0.0326,  0.0421,  ..., -0.0217, -0.2104, -0.1832],\n",
       "           [-0.0037,  0.0492,  0.0170,  ..., -0.0331, -0.1426, -0.0393],\n",
       "           ...,\n",
       "           [-0.0109, -0.0129,  0.1177,  ..., -0.0325,  0.0743, -0.0249],\n",
       "           [ 0.0192, -0.0745, -0.0131,  ...,  0.0036,  0.0304,  0.0475],\n",
       "           [ 0.0754, -0.2283, -0.0353,  ...,  0.1660,  0.1223,  0.1599]]],\n",
       "         device='cuda:1'),\n",
       "  tensor([[[-0.1407,  0.2404, -0.1800,  ..., -0.2678,  0.1516,  0.2967],\n",
       "           [ 0.1969,  0.0040,  0.1912,  ..., -0.0699, -0.2717, -0.1719],\n",
       "           [ 0.0389, -0.3336,  0.0783,  ..., -0.2334, -0.1037, -0.0278],\n",
       "           ...,\n",
       "           [-0.0934, -0.0470,  0.2830,  ...,  0.0494,  0.1655, -0.1319],\n",
       "           [ 0.0257, -0.0840,  0.2379,  ...,  0.0363,  0.1024,  0.0253],\n",
       "           [ 0.1851, -0.0785,  0.1004,  ...,  0.2740, -0.1668,  0.2082]]],\n",
       "         device='cuda:2'),\n",
       "  tensor([[[-0.1666,  0.2400, -0.1867,  ..., -0.2691,  0.2106,  0.2900],\n",
       "           [ 0.0226,  0.2493,  0.2098,  ..., -0.0589, -0.0918, -0.3449],\n",
       "           [ 0.0568, -0.5060,  0.1217,  ..., -0.3020, -0.0503, -0.0933],\n",
       "           ...,\n",
       "           [-0.2350, -0.2444,  0.3816,  ...,  0.0316,  0.1756, -0.0654],\n",
       "           [ 0.0744,  0.0179,  0.3469,  ..., -0.0542,  0.0508, -0.0937],\n",
       "           [ 0.1812, -0.0245,  0.0443,  ...,  0.2869, -0.2438,  0.3332]]],\n",
       "         device='cuda:2'),\n",
       "  tensor([[[-0.1454,  0.2235, -0.2083,  ..., -0.2361,  0.2558,  0.3205],\n",
       "           [-0.1363,  0.1633,  0.3208,  ..., -0.0795, -0.2098, -0.3870],\n",
       "           [-0.0958, -0.6070,  0.0797,  ..., -0.3056,  0.1178, -0.0652],\n",
       "           ...,\n",
       "           [-0.0832, -0.2184,  0.3727,  ..., -0.0313,  0.2796, -0.2519],\n",
       "           [ 0.0840, -0.0893,  0.3547,  ..., -0.0365,  0.0881, -0.1425],\n",
       "           [ 0.2384, -0.1000,  0.0474,  ...,  0.3192, -0.2418,  0.3603]]],\n",
       "         device='cuda:2'),\n",
       "  tensor([[[-0.1240,  0.2345, -0.1423,  ..., -0.2473,  0.3008,  0.3514],\n",
       "           [-0.1715,  0.1344,  0.4238,  ..., -0.1664, -0.0730, -0.1086],\n",
       "           [-0.2033, -0.6603,  0.1506,  ..., -0.5958,  0.1220, -0.0272],\n",
       "           ...,\n",
       "           [ 0.1790, -0.1602,  0.2139,  ..., -0.1326,  0.1059, -0.0480],\n",
       "           [ 0.2967, -0.2199,  0.2740,  ..., -0.2539, -0.3435, -0.0153],\n",
       "           [ 0.2239, -0.0437,  0.0631,  ...,  0.1290, -0.2684,  0.2814]]],\n",
       "         device='cuda:3'),\n",
       "  tensor([[[-0.0887,  0.2082, -0.0655,  ..., -0.2430,  0.4027,  0.3992],\n",
       "           [-0.1577, -0.0280,  0.3798,  ..., -0.4831,  0.0523, -0.1023],\n",
       "           [-0.0668, -0.8573,  0.1422,  ..., -0.7827,  0.2245, -0.0051],\n",
       "           ...,\n",
       "           [ 0.1537, -0.2373,  0.1202,  ..., -0.3051,  0.1241, -0.3835],\n",
       "           [ 0.2756, -0.3567,  0.3436,  ..., -0.3829, -0.1173, -0.2196],\n",
       "           [ 0.2226, -0.1226,  0.0368,  ...,  0.1188, -0.2376,  0.2753]]],\n",
       "         device='cuda:3'),\n",
       "  tensor([[[-0.1006,  0.1621, -0.0135,  ..., -0.2128,  0.4861,  0.3996],\n",
       "           [-0.4129,  0.0127,  0.4700,  ..., -0.5363, -0.0266, -0.2553],\n",
       "           [-0.2175, -0.9680, -0.0668,  ..., -0.5890,  0.1774, -0.0266],\n",
       "           ...,\n",
       "           [ 0.0840, -0.2877,  0.1761,  ..., -0.1886,  0.1132, -0.5753],\n",
       "           [ 0.1368, -0.4700,  0.2673,  ..., -0.3060, -0.2094, -0.4775],\n",
       "           [ 0.1584, -0.2111,  0.0094,  ...,  0.0831, -0.1694,  0.2541]]],\n",
       "         device='cuda:3'),\n",
       "  tensor([[[-0.0932,  0.2183,  0.0136,  ..., -0.1411,  0.5482,  0.3907],\n",
       "           [-0.5757,  0.0971,  0.4738,  ..., -0.4666,  0.1435, -0.2061],\n",
       "           [-0.3660, -1.0741, -0.1577,  ..., -0.4938,  0.3371,  0.2273],\n",
       "           ...,\n",
       "           [ 0.4964, -0.3560,  0.4354,  ...,  0.2896, -0.1195, -0.4927],\n",
       "           [ 0.6182, -0.4179,  0.2827,  ...,  0.0131, -0.3259, -0.4184],\n",
       "           [ 0.1675, -0.1907, -0.0219,  ...,  0.1664, -0.1554,  0.1941]]],\n",
       "         device='cuda:4'),\n",
       "  tensor([[[-0.1197,  0.2400,  0.0701,  ..., -0.0144,  0.5812,  0.4755],\n",
       "           [-0.3925, -0.2123,  0.4583,  ..., -0.5323, -0.0049, -0.1590],\n",
       "           [-0.3824, -1.1803, -0.0915,  ..., -0.6536,  0.3768,  0.1765],\n",
       "           ...,\n",
       "           [ 0.5661, -0.5512,  0.8352,  ...,  0.5987,  0.0202, -0.1010],\n",
       "           [ 0.6602, -0.6490,  0.6909,  ...,  0.3372, -0.2432,  0.1855],\n",
       "           [ 0.1838, -0.3152,  0.0216,  ...,  0.1368, -0.0939,  0.1727]]],\n",
       "         device='cuda:4'),\n",
       "  tensor([[[-0.0929,  0.2144,  0.0586,  ...,  0.0341,  0.4834,  0.3849],\n",
       "           [-0.4951, -0.0778,  0.5396,  ..., -0.4864, -0.0252, -0.1641],\n",
       "           [-0.1539, -1.1369, -0.2280,  ..., -1.1513,  0.4112,  0.0918],\n",
       "           ...,\n",
       "           [ 0.8460, -0.3028,  0.8691,  ...,  1.3532, -0.0263, -0.1832],\n",
       "           [ 0.9365, -0.3660,  0.8292,  ...,  1.1927, -0.1335,  0.2951],\n",
       "           [ 0.3490, -0.2863, -0.0248,  ...,  0.1977, -0.1464,  0.2547]]],\n",
       "         device='cuda:4'),\n",
       "  tensor([[[-0.1032,  0.2020,  0.1254,  ...,  0.0813,  0.4854,  0.4142],\n",
       "           [-0.3895, -0.0458,  0.2292,  ..., -0.9030,  0.3351, -0.2023],\n",
       "           [-0.3381, -1.0268, -0.5145,  ..., -1.1873,  0.6541,  0.0626],\n",
       "           ...,\n",
       "           [ 0.3706, -0.2806,  0.9660,  ...,  1.5548, -0.0284, -0.3349],\n",
       "           [ 0.5360, -0.2726,  1.1204,  ...,  1.1052, -0.0208,  0.0840],\n",
       "           [ 0.3080, -0.2051, -0.0520,  ...,  0.2309, -0.1395,  0.4069]]],\n",
       "         device='cuda:5'),\n",
       "  tensor([[[-6.9875e-02,  2.0176e-01,  1.4870e-01,  ...,  1.0223e-01,\n",
       "             4.7905e-01,  3.7846e-01],\n",
       "           [ 1.3507e-01, -9.5626e-02,  2.7922e-01,  ..., -1.0457e+00,\n",
       "            -1.2955e-01, -2.1236e-01],\n",
       "           [-2.3470e-02, -1.2806e+00, -4.1174e-01,  ..., -1.3404e+00,\n",
       "             2.7490e-04, -2.0026e-02],\n",
       "           ...,\n",
       "           [ 5.3748e-01, -9.6223e-02,  1.6045e+00,  ...,  1.3742e+00,\n",
       "             9.0011e-02, -8.8553e-01],\n",
       "           [ 8.1569e-01,  9.0464e-02,  1.6859e+00,  ...,  1.1859e+00,\n",
       "             1.9662e-01, -6.0400e-01],\n",
       "           [ 4.6511e-01, -1.5351e-01, -2.3906e-02,  ...,  2.2443e-01,\n",
       "            -1.6461e-01,  3.6173e-01]]], device='cuda:5'),\n",
       "  tensor([[[-0.1545,  0.1974,  0.0781,  ...,  0.1925,  0.4569,  0.4860],\n",
       "           [ 0.3439, -0.2431,  0.7773,  ..., -0.8995, -0.3299, -0.5237],\n",
       "           [-0.0286, -1.7528, -0.0384,  ..., -1.1723,  0.2347, -0.0049],\n",
       "           ...,\n",
       "           [ 0.4173,  0.0291,  1.0580,  ...,  0.9826, -0.1613, -1.0139],\n",
       "           [ 0.6645,  0.3768,  1.2186,  ...,  0.8439, -0.1696, -0.6260],\n",
       "           [ 0.4428, -0.1543, -0.1247,  ...,  0.2733, -0.1565,  0.3735]]],\n",
       "         device='cuda:5'),\n",
       "  tensor([[[-0.1932,  0.2144,  0.1592,  ...,  0.0878,  0.4150,  0.4904],\n",
       "           [ 0.3743, -0.0350,  0.8390,  ..., -0.9632, -0.3328, -0.2140],\n",
       "           [ 0.2482, -1.6885,  0.0216,  ..., -0.6546, -0.0225,  0.4456],\n",
       "           ...,\n",
       "           [ 0.6110,  0.1816,  1.2246,  ...,  0.9789,  0.0714, -0.6874],\n",
       "           [ 0.7108,  0.4221,  1.4010,  ...,  0.7385,  0.1501, -0.3999],\n",
       "           [ 0.4428, -0.2048,  0.0670,  ...,  0.3262, -0.1327,  0.3875]]],\n",
       "         device='cuda:6'),\n",
       "  tensor([[[ 0.2047,  0.4874,  0.2460,  ...,  0.0768,  0.0218,  0.3355],\n",
       "           [ 0.6150,  0.3625,  0.6258,  ..., -1.1971, -0.4662, -0.5604],\n",
       "           [ 0.1093, -1.5262, -0.1445,  ..., -0.9030, -0.3207, -0.0420],\n",
       "           ...,\n",
       "           [ 0.9037,  0.1396,  1.0047,  ...,  1.2713,  0.1219, -0.5383],\n",
       "           [ 1.0080,  0.3117,  1.2779,  ...,  1.0835,  0.1883, -0.1970],\n",
       "           [ 0.8208,  0.0960,  0.1089,  ...,  0.3678, -0.3455,  0.3889]]],\n",
       "         device='cuda:6'),\n",
       "  tensor([[[ 0.2897,  0.4034,  0.2902,  ..., -0.0288, -0.1720,  0.2523],\n",
       "           [ 0.6396,  0.7315,  0.6163,  ..., -0.8795, -0.3638, -0.1768],\n",
       "           [-0.2179, -1.8386, -0.1017,  ..., -0.7853, -0.3910,  0.4610],\n",
       "           ...,\n",
       "           [ 1.0313,  0.2352,  0.7080,  ...,  1.5553,  0.1717, -0.2987],\n",
       "           [ 1.1497,  0.6750,  0.9597,  ...,  1.2995,  0.0788,  0.2827],\n",
       "           [ 0.7792, -0.1133,  0.0465,  ...,  0.3646, -0.3418,  0.4961]]],\n",
       "         device='cuda:6'),\n",
       "  tensor([[[ 0.3253,  0.3963,  0.2167,  ..., -0.0580, -0.1132,  0.2534],\n",
       "           [ 0.5214,  1.0506,  0.6649,  ..., -0.8564, -0.5986, -0.1017],\n",
       "           [-0.8566, -1.6256,  0.2820,  ..., -1.0475, -0.3614,  0.9748],\n",
       "           ...,\n",
       "           [ 1.1585,  1.2689,  1.0292,  ...,  1.6885,  0.7258, -0.3374],\n",
       "           [ 1.3397,  1.4565,  1.3393,  ...,  1.4388,  0.4757,  0.2147],\n",
       "           [ 0.8528, -0.1295,  0.0416,  ...,  0.3752, -0.2657,  0.6152]]],\n",
       "         device='cuda:7'),\n",
       "  tensor([[[ 5.8134e-01,  2.9605e-01,  2.4561e-01,  ..., -3.3101e-01,\n",
       "            -1.6508e-01,  2.9207e-01],\n",
       "           [ 3.8567e-01,  1.0399e+00,  6.2846e-01,  ..., -5.7190e-01,\n",
       "            -1.3625e-01, -8.3505e-02],\n",
       "           [-4.1770e-01, -1.9043e+00,  7.2369e-01,  ..., -8.9579e-01,\n",
       "            -4.8155e-01,  1.2883e+00],\n",
       "           ...,\n",
       "           [ 9.7460e-01,  1.4612e+00,  7.0510e-01,  ...,  2.2659e+00,\n",
       "             1.0030e+00,  2.3627e-01],\n",
       "           [ 1.2289e+00,  1.7709e+00,  1.1508e+00,  ...,  1.8251e+00,\n",
       "             5.7551e-01,  9.4971e-01],\n",
       "           [ 1.0458e+00, -2.1821e-01, -1.9272e-03,  ...,  3.5736e-01,\n",
       "            -2.2491e-01,  6.3980e-01]]], device='cuda:7'),\n",
       "  tensor([[[ 0.5972,  0.3000,  0.2288,  ..., -0.3101, -0.1605,  0.3594],\n",
       "           [ 0.3903,  0.7996,  0.7593,  ..., -0.4926, -0.2841,  0.3740],\n",
       "           [-0.2186, -2.0492,  0.2005,  ..., -0.9594, -0.8257,  1.5849],\n",
       "           ...,\n",
       "           [ 1.0689,  1.5679,  1.2947,  ...,  2.7838,  0.7550,  0.7603],\n",
       "           [ 1.1612,  1.5372,  1.8029,  ...,  2.4107,  0.5022,  1.5572],\n",
       "           [ 1.0927, -0.2187, -0.0417,  ...,  0.5102, -0.2291,  0.6553]]],\n",
       "         device='cuda:7'),\n",
       "  tensor([[[ 0.6953,  0.2809,  0.2337,  ..., -0.2253, -0.1365,  0.3614],\n",
       "           [ 0.2734,  1.0493,  1.0733,  ..., -0.4305, -0.2825,  0.1902],\n",
       "           [ 0.2153, -2.0233,  0.4168,  ..., -1.2616, -0.4408,  1.6088],\n",
       "           ...,\n",
       "           [ 1.0594,  1.8016,  1.5787,  ...,  3.1006,  0.3896,  1.4243],\n",
       "           [ 1.0049,  1.3363,  2.1038,  ...,  2.6076,  0.3032,  1.9071],\n",
       "           [ 1.1865, -0.1222,  0.0616,  ...,  0.5878, -0.2399,  0.5597]]],\n",
       "         device='cuda:8'),\n",
       "  tensor([[[ 0.7243,  0.2721,  0.2637,  ..., -0.2536, -0.1499,  0.3507],\n",
       "           [ 0.3342,  0.8286,  1.5163,  ..., -0.4923, -0.2244,  0.3810],\n",
       "           [ 0.6130, -2.2975,  0.7172,  ..., -1.3269, -0.2152,  1.2820],\n",
       "           ...,\n",
       "           [ 1.5858,  1.7132,  1.4107,  ...,  3.5215, -0.0209,  0.6798],\n",
       "           [ 1.2323,  1.0398,  2.0205,  ...,  3.0094, -0.6068,  1.5562],\n",
       "           [ 1.1854, -0.0801,  0.1566,  ...,  0.7715, -0.1855,  0.5221]]],\n",
       "         device='cuda:8'),\n",
       "  tensor([[[ 0.7685,  0.2355,  0.3316,  ..., -0.2418, -0.1801,  0.3484],\n",
       "           [-0.0368,  0.9455,  1.0422,  ..., -0.2390, -0.1367,  0.1621],\n",
       "           [ 0.5236, -2.1445,  0.3293,  ..., -1.4567, -0.0267,  1.6634],\n",
       "           ...,\n",
       "           [ 2.3629,  1.8612,  1.6931,  ...,  3.1803, -0.5538,  0.9596],\n",
       "           [ 1.3757,  1.3188,  1.8233,  ...,  3.1939, -1.0387,  2.1181],\n",
       "           [ 1.1370,  0.0628,  0.2868,  ...,  0.8792, -0.2360,  0.5209]]],\n",
       "         device='cuda:8'),\n",
       "  tensor([[[ 7.9575e-01,  1.8084e-01,  3.1960e-01,  ..., -2.2740e-01,\n",
       "            -2.2183e-01,  3.6345e-01],\n",
       "           [ 3.1812e-03,  9.2387e-01,  1.1355e+00,  ..., -5.1784e-01,\n",
       "            -4.5563e-01, -4.7315e-01],\n",
       "           [ 6.5833e-01, -2.0889e+00,  5.0653e-01,  ..., -1.9167e+00,\n",
       "            -7.5562e-02,  1.4096e+00],\n",
       "           ...,\n",
       "           [ 2.3809e+00, -3.2205e-01,  2.5685e+00,  ...,  3.7454e+00,\n",
       "            -1.3239e+00,  8.0172e-01],\n",
       "           [ 1.3299e+00, -6.5467e-01,  2.0138e+00,  ...,  3.9019e+00,\n",
       "            -1.9519e+00,  2.0656e+00],\n",
       "           [ 8.8263e-01,  9.4867e-02,  2.5533e-01,  ...,  9.3034e-01,\n",
       "            -4.4181e-01,  4.6771e-01]]], device='cuda:9'),\n",
       "  tensor([[[ 0.9189,  0.1965,  0.3064,  ..., -0.1886, -0.2439,  0.3855],\n",
       "           [ 0.1654,  0.6929,  1.1638,  ..., -0.8023, -0.7899, -0.0846],\n",
       "           [ 0.8032, -1.9805,  0.3742,  ..., -1.6111,  0.0893,  1.7027],\n",
       "           ...,\n",
       "           [ 2.2398, -0.4734,  1.9156,  ...,  4.6337, -1.6313,  1.0166],\n",
       "           [ 1.6378, -0.6704,  1.1044,  ...,  4.0106, -2.6442,  2.7899],\n",
       "           [ 1.1768,  0.1040,  0.0680,  ...,  1.0765, -0.7226,  0.5205]]],\n",
       "         device='cuda:9'),\n",
       "  tensor([[[ 1.0082,  0.2491,  0.2819,  ..., -0.0966, -0.1889,  0.4300],\n",
       "           [ 0.0789,  0.5197,  1.3977,  ..., -0.9469, -1.1178, -0.4899],\n",
       "           [ 0.5230, -1.6659,  0.1934,  ..., -1.2727, -0.3434,  1.1870],\n",
       "           ...,\n",
       "           [ 3.0583, -1.6929,  1.8873,  ...,  3.4300, -1.7585, -0.0980],\n",
       "           [ 2.3663, -1.8593,  1.2229,  ...,  3.6659, -2.9793,  1.8652],\n",
       "           [ 0.9873,  0.0280,  0.6725,  ...,  0.9552, -0.9814,  0.2206]]],\n",
       "         device='cuda:9'),\n",
       "  tensor([[[ 0.8453,  0.1797,  0.2342,  ...,  0.0713, -0.2425,  0.1718],\n",
       "           [ 0.3541,  0.0752,  1.6282,  ..., -0.7816, -0.8279, -0.4604],\n",
       "           [ 1.1115, -1.6037,  0.1472,  ..., -1.4429, -0.3506,  1.8990],\n",
       "           ...,\n",
       "           [ 3.2080, -1.2008,  2.0186,  ...,  3.4607, -2.1103,  0.5673],\n",
       "           [ 1.2728, -1.2176,  1.0613,  ...,  3.2770, -2.8546,  2.7527],\n",
       "           [-0.7385,  0.2310,  0.6344,  ...,  1.6117, -1.6004, -1.7757]]],\n",
       "         device='cuda:10'),\n",
       "  tensor([[[ 0.9589,  0.2578,  0.2179,  ...,  0.1619, -0.0978,  0.0712],\n",
       "           [ 0.7165, -0.2477,  1.8343,  ..., -0.1157, -0.8448, -0.3599],\n",
       "           [ 2.4262, -1.5640, -0.1912,  ..., -0.9821, -0.2966,  1.8615],\n",
       "           ...,\n",
       "           [ 1.8332, -1.5471,  3.7739,  ...,  4.1013, -1.3953,  0.2966],\n",
       "           [ 0.4864, -0.8538,  2.4648,  ...,  3.4448, -1.0804,  2.8144],\n",
       "           [-0.3685,  0.3917,  1.0950,  ...,  1.9205, -1.7247, -1.7376]]],\n",
       "         device='cuda:10'),\n",
       "  tensor([[[-0.4780,  0.1359, -0.6939,  ..., -0.1296, -0.0650, -0.9227],\n",
       "           [ 0.4578, -1.1879,  2.7623,  ...,  0.6299, -1.3336,  0.1901],\n",
       "           [ 2.9541, -0.7286,  0.2106,  ..., -0.4136, -0.4036,  2.6728],\n",
       "           ...,\n",
       "           [ 0.4445, -0.6871,  4.5664,  ...,  3.4155,  1.6329, -0.2026],\n",
       "           [-0.8559, -1.2313,  4.1507,  ...,  2.3245,  1.5132,  3.1469],\n",
       "           [-0.3673, -0.0869,  1.6974,  ...,  2.3639, -1.2962, -0.8539]]],\n",
       "         device='cuda:10'),\n",
       "  tensor([[[ 1.7729, -1.4340,  0.3075,  ..., -0.5573,  0.0064, -0.7626],\n",
       "           [-2.1269, -1.0881,  0.1922,  ...,  0.5358, -1.3013, -0.1749],\n",
       "           [-3.6840,  0.4955, -0.6878,  ...,  0.9461,  0.0840,  0.6209],\n",
       "           ...,\n",
       "           [ 0.0925, -0.5180,  2.2729,  ...,  0.3876, -0.2024, -2.4149],\n",
       "           [-1.5827, -1.5720,  3.3173,  ...,  0.2413,  0.7279,  1.1369],\n",
       "           [ 1.3438, -1.2516,  3.3698,  ..., -0.2226, -2.2946, -1.2497]]],\n",
       "         device='cuda:11')),\n",
       " 'attentions': None}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz4.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['last_hidden_state', 'past_key_values', 'hidden_states', 'attentions'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz4.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_embeds = model.get_decoder().embed_tokens(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7729, -1.4340,  0.3075,  ..., -0.5573,  0.0064, -0.7626],\n",
       "         [-2.1269, -1.0881,  0.1922,  ...,  0.5358, -1.3013, -0.1749],\n",
       "         [-3.6840,  0.4955, -0.6878,  ...,  0.9461,  0.0840,  0.6209],\n",
       "         ...,\n",
       "         [ 0.0925, -0.5180,  2.2729,  ...,  0.3876, -0.2024, -2.4149],\n",
       "         [-1.5827, -1.5720,  3.3173,  ...,  0.2413,  0.7279,  1.1369],\n",
       "         [ 1.3438, -1.2516,  3.3698,  ..., -0.2226, -2.2946, -1.2497]]],\n",
       "       device='cuda:11')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz4.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7729, -1.4340,  0.3075,  ..., -0.5573,  0.0064, -0.7626],\n",
       "         [-2.1269, -1.0881,  0.1922,  ...,  0.5358, -1.3013, -0.1749],\n",
       "         [-3.6840,  0.4955, -0.6878,  ...,  0.9461,  0.0840,  0.6209],\n",
       "         ...,\n",
       "         [ 0.0925, -0.5180,  2.2729,  ...,  0.3876, -0.2024, -2.4149],\n",
       "         [-1.5827, -1.5720,  3.3173,  ...,  0.2413,  0.7279,  1.1369],\n",
       "         [ 1.3438, -1.2516,  3.3698,  ..., -0.2226, -2.2946, -1.2497]]],\n",
       "       device='cuda:11')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz4.hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:11')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(zzz4.last_hidden_state == zzz4.hidden_states[-1]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### last token's last hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz4.last_hidden_state[0][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 139, 4096])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inputs_embeds == zzz4.hidden_states[0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 139, 4096])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz4.hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 139, 4096])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz4.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zzz4.hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_hidden_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'logits', 'past_key_values', 'hidden_states', 'attentions'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz3.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CausalLMOutputWithPast' object has no attribute 'last_hidden_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mzzz3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CausalLMOutputWithPast' object has no attribute 'last_hidden_state'"
     ]
    }
   ],
   "source": [
    "zzz3.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qlora_conda_3912_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
